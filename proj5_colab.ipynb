{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Dv8absVKufcA",
   "metadata": {
    "id": "Dv8absVKufcA"
   },
   "source": [
    "# Semantic Segmentation with Deep Learning: Training and Testing on Colab\n",
    "\n",
    "Insert the following Javascript snippet into your browser console so that your Colab runtime won't time out. Open developer-settings (in your web-browser) with Ctrl+Shift+I then click on console tab and type this on the console prompt. (for mac press Option+Command+I)\n",
    "```Javascript\n",
    "function ClickConnect(){\n",
    "    console.log(\"Clicked on connect button\"); \n",
    "    document.querySelector(\"colab-connect-button\").click()\n",
    "}\n",
    "setInterval(ClickConnect,60000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdweXW5Xqd6R",
   "metadata": {
    "id": "bdweXW5Xqd6R"
   },
   "source": [
    "Zip up your code locally with `python zip_for_colab.py`, and upload your `cv_proj5.zip` file. Hit refresh, then run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ah8PNwYTqM1G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ah8PNwYTqM1G",
    "outputId": "37b569ff-8d07-44d1-c377-64c59873463f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip cv_proj5_colab.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0pf627lnqsTo",
   "metadata": {
    "id": "0pf627lnqsTo"
   },
   "source": [
    "Install the `proj6_code` module locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sEkEfbqNqxa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEkEfbqNqxa4",
    "outputId": "9bedd832-b787-4408-c90b-0fcc1d1b6c90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-franchise",
   "metadata": {
    "id": "sensitive-franchise"
   },
   "source": [
    "Download ImageNet-pretrained ResNet-50:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bound-explosion",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bound-explosion",
    "outputId": "5f868037-5acb-40ba-95eb-7d6e528d50b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'id' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -O \"resnet50_v2.pth\" --no-check-certificate 'https://docs.google.com/uc?export=download&id=1w5pRmLJXvmQQA5PtCbHhZc_uC4o0YbmA'\n",
    "!mkdir initmodel && mv resnet50_v2.pth initmodel/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "yZDeFtlyuXNz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZDeFtlyuXNz",
    "outputId": "bb3cd374-2407-4d76-e7ba-e79059d00a91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# The ImageNet-pretrained ResNet-50 weights should be 99 MB\n",
    "!ls -ltrh initmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7wzfFzyHupog",
   "metadata": {
    "id": "7wzfFzyHupog"
   },
   "source": [
    "Download the Camvid dataset images. It's 700 MB, but it should only take 30 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intellectual-delaware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "intellectual-delaware",
    "outputId": "7079f327-3199-44c1-e494-73efc9398245"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'sed' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'.' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!chmod +rwx download_dataset.sh\n",
    "!sed -i -e 's/\\r$//' download_dataset.sh\n",
    "!./download_dataset.sh Camvid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "PGBUoTc9Aj0t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGBUoTc9Aj0t",
    "outputId": "8e0536ff-cc94-4976-f606-0146348f03ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!cd Camvid && unzip camvid_semseg11.zip && cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AC_-gfRptGgF",
   "metadata": {
    "id": "AC_-gfRptGgF"
   },
   "source": [
    "We'll now set some default hyperparameters for training. Choose the number of epochs you'd like to train for (for PSPNet, it will take ~30 min for 50 epochs, or ~70 min for 100 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "absent-major",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "absent-major",
    "outputId": "86019d3c-bd91-42c1-9e06-7a68f711f000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.6\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "from types import SimpleNamespace\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    **{\n",
    "        # DATA\n",
    "        \"names_path\": \"./dataset_lists/camvid-11/camvid-11_names.txt\",\n",
    "        \"data_root\": \"./Camvid/\",\n",
    "        \"train_list\": \"./src/dataset_lists/camvid-11/list/train.txt\",  \n",
    "        \"val_list\": \"./src/dataset_lists/camvid-11/list/val.txt\",\n",
    "        \"classes\": 11,\n",
    "        # TRAIN\n",
    "        \"arch\": \"PSPNet\", #  \"SimpleSegmentationNet\", # \n",
    "        \"save_path\": \"\",\n",
    "        \"epochs\": 5,\n",
    "        \"zoom_factor\": 8,\n",
    "        \"use_ppm\": True,\n",
    "        \"aux_weight\": 0.4,\n",
    "        \"aux_loss\": True,\n",
    "        \"layers\": 50,\n",
    "        \"workers\": 2,\n",
    "        \"batch_size\": 32,\n",
    "        \"batch_size_val\": 32,\n",
    "        \"data_aug\": True,\n",
    "        \"short_size\": 240,\n",
    "        \"train_h\": 201,\n",
    "        \"train_w\": 201,\n",
    "        \"init_weight\": \"./initmodel/resnet50_v2.pth\",\n",
    "        \"scale_min\": 0.5,  # minimum random scale\n",
    "        \"scale_max\": 2.0,  # maximum random scale\n",
    "        \"rotate_min\": -10,  # minimum random rotate\n",
    "        \"rotate_max\": 10,  # maximum random rotate\n",
    "        \"ignore_label\": 255,\n",
    "        \"base_lr\": 0.01,\n",
    "        \"start_epoch\": 0,\n",
    "        \"power\": 0.9,\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"manual_seed\": 0,\n",
    "        \"print_freq\": 10,\n",
    "        \"save_freq\": 1,\n",
    "        \"evaluate\": True,  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend\n",
    "        \"multiprocessing_distributed\": False,\n",
    "        # INFERENCE\n",
    "        \"dataset\": \"camvid-11\",\n",
    "        \"base_size\": 240,\n",
    "        \"test_h\": 201,\n",
    "        \"test_w\": 201,\n",
    "        \"scales\": [1.0], # [0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        \"test_list\": \"./src/dataset_lists/camvid-11/list/val.txt\",\n",
    "        \"vis_freq\": 10,\n",
    "        \"pretrained\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "args.save_path = f\"exp/camvid/{args.arch}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "increased-blade",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "increased-blade",
    "outputId": "be097290-c24a-44d2-b6d5-c2399f88d883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(names_path='./dataset_lists/camvid-11/camvid-11_names.txt', data_root='./Camvid/', train_list='./src/dataset_lists/camvid-11/list/train.txt', val_list='./src/dataset_lists/camvid-11/list/val.txt', classes=11, arch='PSPNet', save_path='exp/camvid/PSPNet/model', epochs=5, zoom_factor=8, use_ppm=True, aux_weight=0.4, aux_loss=True, layers=50, workers=2, batch_size=32, batch_size_val=32, data_aug=True, short_size=240, train_h=201, train_w=201, init_weight='./initmodel/resnet50_v2.pth', scale_min=0.5, scale_max=2.0, rotate_min=-10, rotate_max=10, ignore_label=255, base_lr=0.01, start_epoch=0, power=0.9, momentum=0.9, weight_decay=0.0001, manual_seed=0, print_freq=10, save_freq=1, evaluate=True, multiprocessing_distributed=False, dataset='camvid-11', base_size=240, test_h=201, test_w=201, scales=[1.0], test_list='./src/dataset_lists/camvid-11/list/val.txt', vis_freq=10, pretrained=True)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "`get_model_and_optimizer()` function in `part3_training_utils.py` needs to be implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m main_worker\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(args)\n\u001b[1;32m----> 8\u001b[0m main_worker(args, torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mis_available())\n",
      "File \u001b[1;32mD:\\OneDrive - Georgia Institute of Technology\\Semesters\\6. Fall 2022\\CS 6476 (Computer Vision)\\Projects\\Project 5\\project-5\\src\\vision\\trainer.py:58\u001b[0m, in \u001b[0;36mmain_worker\u001b[1;34m(args, use_cuda)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain_worker\u001b[39m(args, use_cuda: \u001b[39mbool\u001b[39m):\n\u001b[0;32m     57\u001b[0m     \u001b[39m\"\"\" \"\"\"\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     model, optimizer \u001b[39m=\u001b[39m get_model_and_optimizer(args)\n\u001b[0;32m     59\u001b[0m     logger\u001b[39m.\u001b[39minfo(args)\n\u001b[0;32m     60\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m=> creating model ...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\OneDrive - Georgia Institute of Technology\\Semesters\\6. Fall 2022\\CS 6476 (Computer Vision)\\Projects\\Project 5\\project-5\\src\\vision\\part3_training_utils.py:36\u001b[0m, in \u001b[0;36mget_model_and_optimizer\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mCreate your model, optimizer and configure the initial learning rates.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m       SimpleSegmentationNet\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m###########################################################################\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m# TODO: YOUR CODE HERE                                                    #\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m###########################################################################\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`get_model_and_optimizer()` function in \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[0;32m     37\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`part3_training_utils.py` needs to be implemented\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[39m###########################################################################\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m#                             END OF YOUR CODE                            #\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m###########################################################################\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m model, optimizer\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: `get_model_and_optimizer()` function in `part3_training_utils.py` needs to be implemented"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "from vision.trainer import main_worker\n",
    "print(args)\n",
    "main_worker(args, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7or_wjTqvX6H",
   "metadata": {
    "id": "7or_wjTqvX6H"
   },
   "source": [
    "We'll now create full-resolution predictions for the full val set, and compute mIoU against the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-vegetation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "worst-vegetation",
    "outputId": "08decf88-2270-4dde-f313-fe2cd75d9dc0"
   },
   "outputs": [],
   "source": [
    "from vision.test import test_model\n",
    "args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_{args.epochs}.pth\"\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ETWCIkf1vfCP",
   "metadata": {
    "id": "ETWCIkf1vfCP"
   },
   "source": [
    "**Important**: Record the mIoU listed in the output above, and the IoU per each class. You can find the results later in `train_epoch_{args.epochs}/camvid-11/720/results.txt`.\n",
    "\n",
    "Now, let's take a look at what our results look like. We'll make a 2x3 image grid with the following structure:\n",
    "\n",
    "|RGB Image | Blended RGB and Ground Truth | Ground Truth \n",
    "|:-: | :-: | :-:\n",
    "| RGB Image | Blended RGB and Prediction | Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cDpIrDQvvBq5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "cDpIrDQvvBq5",
    "outputId": "b63a39b7-04a5-42f8-cc9d-88fb2468c6ab"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rgb_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/rgb_mask_predictions\"\n",
    "\n",
    "def show_image_grid(rgb_predictions_dir: str, img_fname: str) -> None:\n",
    "  img_grid = imageio.imread(f'{rgb_predictions_dir}/{img_fname}')\n",
    "  plt.figure(figsize=(15,7))\n",
    "  plt.imshow(img_grid)\n",
    "  plt.show()\n",
    "\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_07977.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JOxOOpJ-wDHa",
   "metadata": {
    "id": "JOxOOpJ-wDHa"
   },
   "source": [
    "We'll look at more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wJo0THuZvDkU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wJo0THuZvDkU",
    "outputId": "790b3875-5df5-46f4-b9c2-0320e01d22b3"
   },
   "outputs": [],
   "source": [
    "show_image_grid(rgb_predictions_dir, \"0016E5_07997.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08017.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08037.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08057.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08077.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08097.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08117.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08137.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08157.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VFCSB5B23t19",
   "metadata": {
    "id": "VFCSB5B23t19"
   },
   "source": [
    "Now, zip up your predictions on the test set for your best model, **download them locally to your machine**, and submit these to Gradescope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VbYbqcNn3eS2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbYbqcNn3eS2",
    "outputId": "85f5c7aa-3e2e-48b3-cd31-bc255e8160ef"
   },
   "outputs": [],
   "source": [
    "grayscale_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/gray\"\n",
    "!ls -ltrh $grayscale_predictions_dir\n",
    "!zip -r grayscale_predictions.zip $grayscale_predictions_dir\n",
    "!ls -ltrh grayscale_predictions.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e5d36",
   "metadata": {},
   "source": [
    "In this section you will load the model trained on the Camvid-11 dataset and train it on the Kitti Road Segmentation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foAbZe_L38S9",
   "metadata": {
    "id": "foAbZe_L38S9"
   },
   "outputs": [],
   "source": [
    "args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_{args.epochs}.pth\"\n",
    "args.data_root = \"./kitti\"\n",
    "args.classes = 2\n",
    "args.save_path = f\"exp/kitti/{args.arch}/model\"\n",
    "args.batch_size = 32\n",
    "args.batch_size_val = 1\n",
    "args.dataset = \"kitti\"\n",
    "args.evaluate = False\n",
    "args.epochs = 20\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.base_lr = 0.01\n",
    "args.momentum = 0.9\n",
    "args.weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vision.trainer import transfer_train\n",
    "transfer_train(args, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb177e31",
   "metadata": {},
   "source": [
    "## Don't forget to download the grayscale_predictions.zip and exp folder!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7062ccc1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "proj6_colab2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('cv_proj5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7513e212a8bb9e7ecd9258347352e99d61ea78a5d7a748fe56661332f467eef8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
