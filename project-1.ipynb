{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4476/6476 Project 1: Image Filtering and Hybrid Images\n",
    "\n",
    "All projects in this course will be executed within an iPython notebook. Using an IPython notebooks is a convenient way for you to quickly and easily interact with the code. A notebook contains many blocks of code, each of which can be run independently. You can run a cell with ctrl+enter or shift+enter (to move to the next cell).\n",
    "\n",
    "\n",
    "## Part 1: NumPy\n",
    "### Setup\n",
    "Before we get started, we'll do a quick check to ensure you've previously installed the `vision` module by running the command `pip install -e .` in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.utils import load_image, save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that didn't throw an error, then you're good to proceed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vision.utils import load_image, save_image\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "image1 = load_image('data/1a_dog.bmp')\n",
    "image2 = load_image('data/1b_cat.bmp')\n",
    "\n",
    "# display the dog and cat images\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image1*255).astype(np.uint8));\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image2*255).astype(np.uint8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create filter\n",
    "\n",
    "You will first need to implement `create_Gaussian_kernel_1D()`  in `part1.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.part1 import create_Gaussian_kernel_1D\n",
    "ksize = 29\n",
    "sigma = 7\n",
    "kernel_1d = create_Gaussian_kernel_1D(ksize, sigma)\n",
    "plt.imshow(kernel_1d.T) # plot (N,1) column vector as (1,N) row vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these two simple test cases to check if the implementation seems correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.utils import verify\n",
    "from tests.test_part1 import (\n",
    "    test_create_Gaussian_kernel_1D,\n",
    "    test_create_Gaussian_kernel_1D_sumsto1,\n",
    "    test_create_Gaussian_kernel_1D_peak\n",
    ")\n",
    "\n",
    "print(verify(test_create_Gaussian_kernel_1D))\n",
    "print(verify(test_create_Gaussian_kernel_1D_sumsto1))\n",
    "print(verify(test_create_Gaussian_kernel_1D_peak))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will need to implement `create_Gaussian_kernel_2D()` (which can use `create_Gaussian_kernel_1D`)  in `part1.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.part1 import create_Gaussian_kernel_2D\n",
    "from vision.utils import verify, PIL_resize\n",
    "from tests.test_part1 import (\n",
    "    test_create_Gaussian_kernel_2D_sumsto1,\n",
    "    test_create_Gaussian_kernel_2D_peak,\n",
    "    test_gaussian_kernel_2D\n",
    ")\n",
    "\n",
    "cutoff_frequency = 7\n",
    "kernel = create_Gaussian_kernel_2D(cutoff_frequency)\n",
    "\n",
    "# let's take a look at the filter!\n",
    "plt.figure(figsize=(4,4)); plt.imshow(kernel);\n",
    "\n",
    "## Verify that the Gaussian kernel was created correctly\n",
    "print(verify(test_create_Gaussian_kernel_1D_sumsto1))\n",
    "print(verify(test_create_Gaussian_kernel_1D_peak))\n",
    "print(verify(test_create_Gaussian_kernel_2D_sumsto1))\n",
    "print(verify(test_create_Gaussian_kernel_2D_peak))\n",
    "print(verify(test_gaussian_kernel_2D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply filter to image\n",
    "The next two functions you need to implement in this project can also be found in `part1.py`. Start by implementing `my_conv2d_numpy`, which takes both a filter and an image, and returns the filtered image. This code block will use your `my_conv2d_numpy` function to create and display a blurry version of image1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.part1 import (\n",
    "    my_conv2d_numpy,\n",
    "    create_hybrid_image\n",
    ")\n",
    "from tests.test_part1 import (\n",
    "    test_my_conv2d_numpy_identity,\n",
    "    test_my_conv2d_numpy_ones_filter,\n",
    "    test_my_conv2d_numpy_nonsquare_filter\n",
    ")\n",
    "\n",
    "blurry_image = my_conv2d_numpy(image1, kernel)\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(1,2,1); plt.imshow(image1)\n",
    "plt.subplot(1,2,2); plt.imshow((blurry_image*255).astype(np.uint8))\n",
    "\n",
    "## Verify that my_conv2d_numpy() was implemented correctly\n",
    "print(verify(test_my_conv2d_numpy_identity))\n",
    "print(verify(test_my_conv2d_numpy_ones_filter))\n",
    "print(verify(test_my_conv2d_numpy_nonsquare_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Filtering\n",
    "\n",
    "Here are a few test cases to help you test `my_conv2d_numpy()`, which you will write. You should verify that you get reasonable output here before using your filtering to construct a hybrid image in `part1.py`. The outputs are all saved and you can include them in your writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = load_image('data/1b_cat.bmp')\n",
    "original_height = test_image.shape[0]\n",
    "original_width = test_image.shape[1]\n",
    "test_image = PIL_resize(test_image, (int(0.7*original_width), int(0.7*original_height)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity filter\n",
    "For the identity filter, the filtering result should look identical to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_filter = np.asarray([[0, 0, 0], [0, 1, 0], [0, 0, 0]])\n",
    "identity_image = my_conv2d_numpy(test_image, identity_filter)\n",
    "plt.imshow(identity_image)\n",
    "done = save_image('results/part1/identity_image.jpg', identity_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small blur with a box filter\n",
    "This filter should remove some high frequencies. (See the effect on the cat's whiskers, for example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_filter = np.ones((3,3)) \n",
    "blur_filter /= np.sum(blur_filter)  # making the filter sum to 1\n",
    "blur_image = my_conv2d_numpy(test_image, blur_filter)\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(1,2,1); plt.imshow(test_image)\n",
    "plt.subplot(1,2,2); plt.imshow(blur_image)\n",
    "done = save_image('results/part1/blur_image.jpg', blur_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oriented filter (Sobel operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_filter = np.asarray([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])  # should respond to horizontal gradients\n",
    "sobel_image = my_conv2d_numpy(test_image, sobel_filter)\n",
    "\n",
    "# 0.5 added because the output image is centered around zero otherwise and mostly black\n",
    "sobel_image = np.clip(sobel_image+0.5, 0.0, 1.0)\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(1,2,1); plt.imshow(test_image)\n",
    "plt.subplot(1,2,2); plt.imshow(sobel_image)\n",
    "done = save_image('results/part1/sobel_image.jpg', sobel_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High pass filter (discrete Laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_filter = np.asarray([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "laplacian_image = my_conv2d_numpy(test_image, laplacian_filter)\n",
    "\n",
    "# 0.5 is added because the output image is centered around zero otherwise and mostly black\n",
    "laplacian_image = np.clip(laplacian_image+0.5, 0.0, 1.0)\n",
    "plt.figure(); plt.imshow(laplacian_image)\n",
    "done = save_image('results/part1/laplacian_image.jpg', laplacian_image)\n",
    "\n",
    "# High pass \"filter\" alternative\n",
    "high_pass_image = test_image - blur_image\n",
    "high_pass_image = np.clip(high_pass_image+0.5, 0.0, 1.0)\n",
    "plt.figure(); plt.imshow(high_pass_image)\n",
    "done = save_image('results/part1/high_pass_image.jpg', high_pass_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hybrid image\n",
    "Next, implement `create_hybrid_image()`, which takes two images and makes a hybrid image using the low frequency content from one image and the high frequency content from another by applying the Gaussian kernel you defined in `create_Gaussian_kernel_2D()`.\n",
    "\n",
    "Experiment with the value of `cutoff_frequency` for each pair of images in `data/`. For each image pair, replace `cutoff_frequencies.txt` with the best cutoff frequency value you find. The value on line *i* of the text file should correspond to _i_-th image pair. This is an important step for Part 2! Feel free to also experiment with which image in each pair you grab the low frequencies from and which image you grab high frequencies from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.utils import vis_image_scales_numpy\n",
    "from tests.test_part1 import test_hybrid_image_np\n",
    "\n",
    "low_frequencies, high_frequencies, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "\n",
    "## Verify that results are as expected\n",
    "print(verify(test_hybrid_image_np))\n",
    "\n",
    "vis = vis_image_scales_numpy(hybrid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow((low_frequencies*255).astype(np.uint8));\n",
    "plt.subplot(1,2,2); plt.imshow(((high_frequencies+0.5)*255).astype(np.uint8));\n",
    "plt.figure(figsize=(20, 20)); plt.imshow(vis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image('results/part1/low_frequencies.jpg', low_frequencies)\n",
    "save_image('results/part1/high_frequencies.jpg', high_frequencies+0.5)\n",
    "save_image('results/part1/hybrid_image.jpg', hybrid_image)\n",
    "save_image('results/part1/hybrid_image_scales.jpg', vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: PyTorch \n",
    "\n",
    "Make sure you have specified a cutoff value in `cutoff_frequencies.txt` for each image pair in `data/` before executing the following blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "from vision.part2_datasets import HybridImageDataset\n",
    "from vision.part2_models import HybridImageModel\n",
    "\n",
    "if not os.path.exists('results/part2/'):\n",
    "        os.makedirs('results/part2/')\n",
    "        \n",
    "data_root = 'data' # if you're using additional data, make sure to change this to '../additional_data'\n",
    "cf_file = 'cutoff_frequencies.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model & dataset\n",
    "Implement `HybridImageModel` and `HybridImageDataset`, found in `part2_models.py` and `part2_datasets.py`, respectively.\n",
    "\n",
    "In the code documentation, you will see a term called \"batch size\", which we will discuss in later projects and lectures. For now, we are using the default value of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "dataset = HybridImageDataset(data_root, cf_file)\n",
    "dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hybrid images\n",
    "This code block will iterate through pairs of images from your dataset and create a hybrid image using the low frequency content from one image and the high frequency content from another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    image_a, image_b, cutoff_frequency = next(data_iter)\n",
    "    low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, cutoff_frequency)\n",
    "    \n",
    "    # saves low frequencies, high frequencies, and hybrid image of each pair of images\n",
    "    torchvision.utils.save_image(low_frequencies, 'results/part2/%d_low_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(high_frequencies+0.5, 'results/part2/%d_high_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(hybrid_image, 'results/part2/%d_hybrid_image.jpg' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify that the results are correct\n",
    "from tests.test_part2 import (\n",
    "    test_low_freq_sq_kernel_pytorch, \n",
    "    test_high_freq_sq_kernel_pytorch,\n",
    "    test_hybrid_image_pytorch\n",
    ")\n",
    "\n",
    "## Verify that the Pytorch results are as expected\n",
    "print(verify(test_low_freq_sq_kernel_pytorch))\n",
    "print(verify(test_high_freq_sq_kernel_pytorch))\n",
    "## Verify that the Pytorch hybrid images are created correctly\n",
    "print(verify(test_hybrid_image_pytorch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid image timing comparison\n",
    "Here, we will compare the runtime of creating hybrid images using your NumPy implementation to using your PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "image1 = load_image('data/1a_dog.bmp')\n",
    "image2 = load_image('data/1b_cat.bmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 1. Notice that we explicitly include `create_Gaussian_kernel()_2D` in the timing of Part 1 but not Part 2. This is because the function is already being called (and therefore timed) inside the forward pass of `HybridImageModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cutoff_frequency = 7\n",
    "kernel = create_Gaussian_kernel_2D(cutoff_frequency)\n",
    "low_frequencies, high_frequencies, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "end = time.time() - start\n",
    "print('Part 1: {:.3f} seconds'.format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "\n",
    "start = time.time()\n",
    "low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, torch.Tensor([cutoff_frequency]))\n",
    "end = time.time() - start\n",
    "print('Part 2: {:.3f} seconds'.format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understanding input/output shapes in PyTorch\n",
    "Up until this point, we have produced a filtered output that has the same dimensions as the input image. Let's explore how you can stack multiple filters, apply them in a single operation using your `my_conv2d_pytorch` implementation in `part3.py`, and see how it affects the output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.test_part3 import test_my_conv2d_pytorch\n",
    "\n",
    "# Verify that feature maps are correctly created\n",
    "print(verify(test_my_conv2d_pytorch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image('data/1a_dog.bmp')\n",
    "\n",
    "# turn HW image into CHW, where C=1 for grayscale\n",
    "image = np.transpose(image, (2,0,1))\n",
    "print('Image has shape: ', image.shape)\n",
    "image = torch.from_numpy(image).unsqueeze(0) #convert to tensor and add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.part3 import my_conv2d_pytorch\n",
    "\n",
    "# stack all the test filters along the channel dimension\n",
    "filter_bank = np.stack(\n",
    "    [\n",
    "        [identity_filter], \n",
    "        [blur_filter],\n",
    "        [sobel_filter], \n",
    "        [laplacian_filter],\n",
    "        [identity_filter], \n",
    "        [blur_filter],\n",
    "        [sobel_filter], \n",
    "        [laplacian_filter],\n",
    "        [identity_filter], \n",
    "        [blur_filter],\n",
    "        [sobel_filter], \n",
    "        [laplacian_filter]\n",
    "    ])\n",
    "print('Filter bank has shape: ', filter_bank.shape)\n",
    "\n",
    "filter_bank = torch.from_numpy(filter_bank).float()\n",
    "# Run the image filtering operation\n",
    "feature_maps = my_conv2d_pytorch(image, filter_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_maps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib requires numpy arrays with a particular shape format (h, w, c) for visualizing images. Here, we split and convert `feature_maps` to the appropriate shape arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(4):  # we are stacking 4 filters in the filter bank\n",
    "    print('Visualization {}:'.format(idx))\n",
    "    feature_map = feature_maps[0, [idx, idx+4, idx+8], :, :]\n",
    "    # (c, h, w) --> (h, w, c) for matplotlib visualization purposes\n",
    "    feature_map = np.transpose(feature_map.numpy(),(1,2,0))\n",
    "    plt.figure()\n",
    "    offset = 0 #offset for vis purposes. sobel and laplace use .5\n",
    "    if idx > 1:\n",
    "        offset = .5\n",
    "    plt.imshow(np.clip(feature_map+offset,0,1))\n",
    "    plt.show()\n",
    "    save_image('results/part3/visualization_{}.jpg'.format(idx), np.clip(feature_map+offset,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Convolution in the Frequency Domain\n",
    "\n",
    "In Part 1, we implemented the convolution operation, by moving a filter over an image and calculating a element-wise product at each pixel. \n",
    "\n",
    "In this section, we will implement the same operation using a different approach. We can do this by representing both the image and filter in the *frequency* domain and applying the *Convolution Theorem*. See the handout for more specific math and broader guidelines.\n",
    "\n",
    "You should use the following functions in this section for operations relating to 2-dimensional Discrete Fourier Transform (FFT):\n",
    "- `np.fft.fft2` and `np.fft.ifft2` - useful for performing FFT and iFFT\n",
    "- `np.fft.ifftshift` - useful for plotting FFT results in a more familiar format\n",
    "- `np.real` - useful for plotting real components of complex results\n",
    "\n",
    "You should not use any other modules or libraries to perform convolution or deconvolution, but using `numpy` to handle the images is still encouraged.\n",
    "\n",
    "### Frequency Domain Convolution\n",
    "\n",
    "Start by implementing `my_conv2d_freq` in `part4.py`. The following cells will help you visualize your results. We are testing with a basic Gaussian filter, so your results should look similar to results with this filter above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.part4 import my_conv2d_freq, my_deconv2d_freq\n",
    "from vision.utils import rgb2gray\n",
    "\n",
    "image = rgb2gray(load_image('data/1a_dog.bmp'))\n",
    "kernel = create_Gaussian_kernel_2D(7)\n",
    "\n",
    "fft_image, fft_kernel, fft_conv_result, conv_result = my_conv2d_freq(image,kernel)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(image, cmap='gray');\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(fft_image))));\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(kernel);\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(fft_kernel))));\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(conv_result, cmap='gray');\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(fft_conv_result))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Domain Deconvolution\n",
    "\n",
    "Next, we will undo this convolution in `my_deconv2d_freq`. The following cells will help you visualize your results. If your deconvolution works properly, you will recover the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_freq, filter_freq, deconv_freq, deconv = my_deconv2d_freq(conv_result, kernel)\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(conv_result, cmap='gray');\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(image_freq))));\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(kernel);\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(filter_freq))));\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(deconv, cmap='gray');\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(deconv_freq))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above have shown us that we can take an image and convolve with a kernel in the frequency domain. We can also reverse this operation if we know the kernel. \n",
    "\n",
    "Let's try with another image. This time, we will start with an image that has already been blurred by a kernel, which we are also given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_kernel = np.load('data/part4/kernel.npy')\n",
    "mystery_image = np.load('data/part4/mystery.npy')\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(1,2,1); plt.imshow(mystery_image, cmap='gray');\n",
    "plt.subplot(1,2,2); plt.imshow(mystery_kernel);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your deconvolution works properly, you will be able to recover the original image given the image and kernel above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_freq, filter_freq, deconv_freq, deconv = my_deconv2d_freq(mystery_image, mystery_kernel)\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(1,2,1); plt.imshow(mystery_image, cmap='gray');\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(image_freq))));\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(mystery_kernel);\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(filter_freq))));\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(deconv, cmap='gray');\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(deconv_freq))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work well, but what happens when we add a small amount of salt and pepper noise? Can we still recover the original image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.0001\n",
    "\n",
    "probs = np.random.random((mystery_image.shape[0], mystery_image.shape[1]))\n",
    "mystery_image[probs < prob] = 0\n",
    "mystery_image[probs > 1 - prob] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_freq, filter_freq, deconv_freq, deconv = my_deconv2d_freq(mystery_image, mystery_kernel)\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(1,2,1); plt.imshow(mystery_image, cmap='gray');\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(image_freq))));\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(mystery_kernel);\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(filter_freq))));\n",
    "\n",
    "plt.figure(figsize=(11,6));\n",
    "plt.subplot(1,2,1); plt.imshow(deconv, cmap='gray');\n",
    "plt.subplot(1,2,2); plt.imshow(np.fft.ifftshift(np.log(np.abs(deconv_freq))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "271816ec5eeb01c8e095e7bd07278d4a94ae344927a4d1835a4f1311be40db7f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
